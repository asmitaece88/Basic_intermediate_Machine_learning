{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa94d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# require gradient on a variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f964bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3629dae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.9463, -0.7820, -0.5577], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe326d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe33e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 969.0587, -800.7357, -571.0603], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88573ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382ec8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e402e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fronzen parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ba95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93188eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28493221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\ASUS/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07aa7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the parameters in the network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## assume a  new data set  with 10 labels \n",
    "# in resnet , classifier  is the last linear layer that is model.fc that is the last layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b75a0710",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4591249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##all the parameters in this model , except for the parameters for model.fc  , are frozen \n",
    "# the only parameters that compute gradients are weights and bias of model.fc\n",
    "# notice that although we register  al the parameters  in the optimizer . the only parameters \n",
    "## that are computing gradients  and hence updating in gradient descent , are the weights and biases in the classifier \n",
    "# the same exclusionaruy functionality is available as a  context manager in torch.no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88b698c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize only the classifier\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7696ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ae54aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
